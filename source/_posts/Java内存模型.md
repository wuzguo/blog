---
title: Java内存模型
date: 2017-06-29 22:38:40 
author: wúzguó
avatar: /blog/images/avatar.png
authorLink: https://wzguo.github.io
authorAbout: https://github.com/wzguo
authorDesc: 一个自强不息，艰苦奋斗的「十八线码农」
categories: 操作系统
tags: 
	- JVM
	- JMM
	- 内存模型
keywords: JVM，JMM，内存模型
photos:
	- /blog/images/201706_1/3.png
description: Java内存模型定义及实现原理的介绍
---

### Java内存模型

#### 一、概述

​    Java内存模型即`Java Memory Model（JMM）`，`JVM`规范试图通过`JMM`来屏蔽各种硬件和操作系统的内存访问差异，实现让Java程序在各种平台下都能达到一致的内存访问效果，规避像C、C++等主流编程语言直接使用物理硬件和操作系统的内存模型，因为不同平台上内存模型的差异可能导致并发访问的时经常出错，不得不针对不同平台编写不同程序的问题，实现**一次编译，到处运行**的设计思想。

####二、Java与线程

1. 并发编程

​    多任务和高并发是现代计算机系统必备的功能，是衡量计算机处理器的能力重要指标。为了减少在**磁盘I/O**、**网络通信**、或者**数据库访问**等耗时操作上造成的计算能力上的资源浪费，多任务处理是其最常用的手段。由于计算机的存储设备与处理器的运算能力之间存在着巨大差距，所以现代计算机系统都不得不加入读写速度尽可能接近处理器运算速度的高速缓存来作为内存与处理器之间的缓冲：**将运算需要使用到的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存之中没这样处理器就无需等待缓慢的内存读写了。**

   基于高速缓存的存储交互很好地解决了处理器与内存的速度矛盾，但是引入了新的问题：**缓存一致性（Cache Coherence）**。在多处理器系统中，每个处理器都有自己的高速缓存，而他们又共享同一主存，如下图所示：多个处理器运算任务都涉及同一块主存，需要一种协议（`MSI`、`MESI`、`MOSI` 等）可以保障数据的一致性。

**Java虚拟机内存模型中定义的内存访问操作与硬件的缓存访问操作是具有可比性的。**

![](/blog/images/201706_1/1.png)

2. 线程的基本概念

​    线程是比进程更轻量级的调度执行单位，线程可以把一个进程的资源分配和执行调度分开，各个线程既可以**共享进程资源（内存地址，文件I/O等）**，又可以独立调度（**线程是CPU的调度基本单位**）。
​    进程和线程的主要差别在于它们是不同的操作系统资源管理方式。进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉。所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。但对于一些要求同时进行并且又要共享某些变量的并发操作，只能用多线程模式不能用多进程模式。
实现线程主要有三种方式：**内核线程实现、用户线程实现 和 使用用户线程加轻量级进程混合实现。**

- 内核线程

内核线程（`Kernel-Level Thread KLT`） 就是直接由操作系统内核支持的线程，这种线程由内核来完成线程切换，内核通过操作调度器（`Thread Scheduler`）对线程进行调度，并负责将线程的任务映射到处理器上，每个内核线程可以视为内核的分身，这样操作系统就有能力同事处理多件事情，支持多线程的内核就叫做多线程内核（`Multi-Threads Kernel`）。**程序一般不会直接去使用内核线程，而是去使用内核线程的一种高级接口 --- 轻量级进程（`Light Weight Process LWP`）。**

- 轻量级进程

​    轻量级进程就是我们通常意义上的线程，由于每个`LWP`都与一个特定的内核线程关联，因此每个`LWP`都是一个独立的线程调度单元。即使有一个`LWP`在系统调用中阻塞，也不会影响整个进程的执行，但是轻量级进程具有局限性：

​    首先，大多数`LWP`的操作，如 建立、析构以及同步都需要进行系统调用，系统调用的代价相对较高，需要在`user mode`和`kernel mode`中切换。

​    其次，每个`LWP`都需要有一个内核线程支持，因此`LWP`要消耗内核资源（内核线程的栈空间），因此一个系统不能支持大量的`LWP`。

![](/blog/images/201706_1/15.png)

- 用户线程

​    `LWP`虽然本质上属于用户线程，但`LWP`线程库是建立在内核之上的，`LWP`的许多操作都要进行系统调用，因此效率不高。而这里的用户线程（`User Thread, UT`）指的是完全建立在用户空间的线程库，用户线程的建立，同步，销毁，调度完全在用户空间完成，不需要内核的帮助。因此这种线程的操作是极其快速的且低消耗的。

![](/blog/images/201706_1/16.png)

​    上图是最初的一个用户线程模型，从中可以看出，进程中包含线程，用户线程在用户空间中实现，内核并没有直接对用户线程进程调度，用户线程之间的调度由在用户空间实现的线程库实现，其缺点是：**一个用户线程如果阻塞在系统调用中，则整个进程都将会阻塞。**

- 使用用户线程加轻量级进程混合实现

​    用户线程库还是完全建立在用户空间中，因此用户线程的操作还是很廉价，因此可以建立任意多需要的用户线程。操作系统提供了`LWP`作为用户线程和内核线程之间的桥梁。`LWP`还是和前面提到的一样，具有内核线程支持，是内核的调度单元，并且用户线程的系统调用要通过`LWP`，因此进程中某个用户线程的阻塞不会影响整个进程的执行。用户线程库将建立的用户线程关联到`LWP`上，`LWP`与用户线程的数量不一定一致。当内核调度到某个`LWP`上时，此时与该`LWP`关联的用户线程就被执行。

![](/blog/images/201706_1/17.png)
​    

​    当多个线程访问一个对象时，如果不用考虑这个线程在运行时环境下的调度和交替执行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获得正确的结果，那这个对象是线程安全的。


3. 线程间的通信

​    通信是指线程之间以何种机制来交换信息。在命令式编程中，线程之间的通信机制有两种：**共享内存和消息传递。**

  - 在共享内存的并发模型里，线程之间共享程序的公共状态，线程之间通过写-读内存中的公共状态来隐式进行通信。


  - 在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显式进行通信。

4. 线程之间的同步

​    同步是指程序用于控制不同线程之间操作发生相对顺序的机制。

- 在共享内存并发模型里，同步是显式进行的。程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行。


   - 在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的。

​    **Java的并发采用的是共享内存模型，Java线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。**如果编写多线程程序的Java程序员不理解隐式进行的线程之间通信的工作机制，很可能会遇到各种奇怪的内存可见性问题。

5. 线程调度

​    线程调度指系统为线程分配处理器使用权的过程，主要有两种调度方式：

   - 协同式调度（`Cooperative Threads-Scheduling`）：线程执行时间由线程自身控制，线程把自己的工作执行完成之后才主动通知系统切换到另外的线程。如果一个线程出错会阻塞整个系统的运行。
   - 抢占式调度（`Preemptive Threads-Scheduling`）：线程的执行时间由系统根据线程的优先级来分配，优先级越高的线程越容易被系统选择执行。如果一个线程出错不会阻塞其他线程。


####三、Java内存模型的抽象

1. 主内存和工作内存

​    Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出**变量（指实例字段、静态字段和构成数组对象的元素，但是不包含局部变量与方法参数，因为局部变量与方法参数是线程私有的，不会被共享）**的底层细节。


　　Java内存模型中规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存（可以与前面将的处理器的高速缓存类比），线程的工作内存中保存了该线程使用到的变量到主内存副本拷贝，线程对变量的所有操作（读取、赋值）都必须在工作内存中进行，而不能直接读写主内存中的变量。不同线程之间无法直接访问对方工作内存中的变量，线程间变量值的传递均需要在主内存来完成，线程、主内存和工作内存的交互关系如下图所示：

![](/blog/images/201706_1/2.png)

关于主内存与工作内存之间具体的交互协议，即如何从主内存拷贝到工作内存、如何从工作内存同步回主内存之类的实现细节，Java定义了8种操作来完成：

| 操作          | 说明                                       |
| ----------- | ---------------------------------------- |
| lock(锁定)    | 作用于主内存的变量，把一个变量标识为一条线程独占的状态              |
| unclock（解锁） | 作用于主内存的变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定 |
| read（读取）    | 作用于主内存的变量，把一个变量的值从主内存传输到线程的工作内存，以便随后的load动作使用 |
| load（载入）    | 作用于工作内存的变量，把read操作从主内存中得到的变量值放入工作内存的变量副本中 |
| use（使用）     | 作用于工作内存的变量，把工作内存中一个变量的值传递给执行引擎           |
| assign（赋值）  | 作用于工作内存的变量，把执行引擎接收到的值赋给工作内存的变量           |
| store（存储）   | 作用于工作内存的变量，把工作内存中一个变量的值传送给主内存中，以便随后的write操作使用 |
| write（写入）   | 作用于主内存的变量，把store操作从工作内存中得到的变量的值放入主内存的变量中 |

如果要把一个变量从主内存复制到工作内存，那就要顺序地执行`read`和`load`操作，如果要把变量从工作内存同步回主内存，那就要顺序地执行`store`和`write`操作，注意**Java内存模型只要求上述两个操作必须顺序地执行，而没有保证是连续执行。**

2. 内存模型的抽象

​    在Java虚拟机中，**所有实例域、静态域和数组元素存储在堆内存中，堆内存在线程之间共享。局部变量`（Local variables）`，方法定义参数和异常处理器参数不会在线程之间共享**，它们不会有内存可见性问题，也不受内存模型的影响。

​    Java线程之间的通信由Java内存模型（`JMM`）控制，**`JMM` 决定一个线程对共享变量的写入何时对另一个线程可见。**从抽象的角度来看，`JMM`定义了线程和主内存之间的抽象关系：**线程之间的共享变量存储在主内存`（main memory）`中，每个线程都有一个私有的本地内存`（local memory）`，本地内存中存储了该线程以读/写共享变量的副本。**本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。Java内存模型的抽象示意图如下：

![](/blog/images/201706_1/3.png)

从上图来看，线程A与线程B之间如要通信的话，必须要经历下面2个步骤：

- 首先，线程A把本地内存A中更新过的共享变量刷新到主内存中去。
- 然后，线程B到主内存中去读取线程A之前已更新过的共享变量。

下面通过示意图来说明这两个步骤：
![](/blog/images/201706_1/4.png)

​    如上图所示，本地内存A和B有主内存中共享变量`x`的副本。假设初始时，这三个内存中的`x`值都为0。线程A在执行时，把更新后的`x`值（假设值为1）临时存放在自己的本地内存A中。当线程A和线程B需要通信时，线程A首先会把自己本地内存中修改后的x值刷新到主内存中，此时主内存中的x值变为了1。随后，线程B到主内存中去读取线程A更新后的`x`值，此时线程B的本地内存的`x`值也变为了1。

​    从整体来看，这两个步骤实质上是线程A在向线程B发送消息，而且这个通信过程必须要经过主内存。JMM通过控制主内存与每个线程的本地内存之间的交互，来为Java程序员提供内存可见性保证。


#### 四、JVM对Java内存模型的实现

​    在JVM内部，Java内存模型把内存分成了两部分：**线程栈区** 和 **堆区**，下图展示了Java内存模型在JVM中的逻辑视图： 

![](/blog/images/201706_1/7.png)

​    `JVM`中运行的每个线程都拥有自己的线程栈，线程栈包含了当前线程执行的方法调用相关信息，我们也把它称作调用栈。随着代码的不断执行，调用栈会不断变化。

​    线程栈还包含了当前方法的所有本地变量信息。一个线程只能读取自己的线程栈，也就是说，线程中的本地变量对其它线程是不可见的。即使两个线程执行的是同一段代码，它们也会各自在自己的线程栈中创建本地变量，因此，每个线程中的本地变量都会有自己的版本。

​    所有原始类型（`boolean`、`byte`、`short`、`char`、`int`、`long`、`float`、`double`）的本地变量都直接保存在线程栈当中，对于它们的值各个线程之间都是独立的。对于原始类型的本地变量，一个线程可以传递一个副本给另一个线程，它们之间是不能共享的。

​    堆区包含了Java应用创建的所有对象信息，不管对象是哪个线程创建的，其中的对象包括原始类型的封装类（如`Byte`、`Integer`、`Long`等）。不管对象是属于一个成员变量还是方法中的本地变量，它都会被存储在堆区。

​    下图展示了调用栈和本地变量都存储在栈区，对象都存储在堆区： 
![](/blog/images/201706_1/8.png)
​    一个本地变量如果是原始类型，那么它会被完全存储到栈区。 一个本地变量也有可能是一个对象的引用，这种情况下，这个本地引用会被存储到栈中，但是对象本身仍然存储在堆区。

​    对于一个对象的成员方法，这些方法中包含本地变量，仍需要存储在栈区，即使它们所属的对象在堆区。 
​    对于一个对象的成员变量，不管它是原始类型还是包装类型，都会被存储到堆区。

​    `static` 类型的变量以及类本身相关信息都会随着类本身存储在堆区。

​    **堆中的对象可以被多线程共享。**如果一个线程获得一个对象的引用，它便可访问这个对象的成员变量。但是对于本地变量，每个线程都会拷贝一份到自己的线程栈中。

​    下图展示了上面描述的过程: 
![](/blog/images/201706_1/9.png)

不管是什么内存模型，最终还是运行在计算机硬件上的，所以我们有必要了解计算机硬件内存架构，下图就简单描述了当代计算机硬件内存架构： 

![](/blog/images/201706_1/10.png)
​ 

   现代计算机一般都有2个以上CPU，而且每个CPU还有可能包含多个核心。因此，如果我们的应用是多线程的话，这些线程可能会在各个CPU核心中并行运行。当一个CPU需要访问主存时，会先读取一部分主存数据到CPU缓存，进而在读取CPU缓存到寄存器。当CPU需要写数据到主存时，同样会先flush寄存器到CPU缓存，然后再在某些节点把缓存数据flush到主存。

####五、Java内存模型和硬件架构之间的桥接
​    正如上面讲到的，Java内存模型和硬件内存架构并不一致。从硬件上看，不管是栈还是堆，大部分数据都会存到主存中，当然一部分栈和堆的数据也有可能会存到CPU寄存器中，如下图所示，Java内存模型和计算机硬件内存架构是一个交叉关系： 

![](/blog/images/201706_1/11.png)

当对象和变量存储到计算机的各个内存区域时，必然会面临一些问题，其中最主要的两个问题是：

- 共享对象对各个线程的可见性

​    当多个线程同时操作同一个共享对象时，如果没有合理的使用 `volatile` 或 `synchronized` 、`Lock` 等，一个线程对共享对象的更新有可能导致其它线程不可见。

​    想象一下我们的共享对象存储在主存，一个CPU中的线程读取主存数据到CPU缓存，然后对共享对象做了更改，但CPU缓存中的更改后的对象还没有flush到主存，此时线程对共享对象的更改对其它CPU中的线程是不可见的。最终就是每个线程最终都会拷贝共享对象，而且拷贝的对象位于不同的CPU缓存中。

​    如图：左边CPU中运行的线程从主存中拷贝共享对象obj到它的CPU缓存，把对象obj的count变量改为2。但这个变更对运行在右边CPU中的线程不可见，因为这个更改还没有flush到主存中： 

![](/blog/images/201706_1/12.png)
​    

​    要解决共享对象可见性这个问题，我们可以使用 `volatile` 关键字。 `volatile` 关键字可以保证变量会直接从主存读取，而对变量的更新也会直接写到主存。**`volatile`原理是基于CPU内存屏障指令实现的**，后面会讲到。

- 共享对象的竞争现象

​    如果多个线程共享一个对象，如果它们同时修改这个共享对象，这就产生了竞争现象。

​    如下图所示，线程A和线程B共享一个对象`obj`。假设线程A从主存读取`obj.count`变量到自己的CPU缓存，同时，线程B也读取了`obj.count`变量到它的CPU缓存，并且这两个线程都对`obj.count`做了加1操作。此时`obj.count`加1操作被执行了两次，不过都在不同的CPU缓存中。

​    如果这两个加1操作是串行执行的，那么`obj.count`变量便会在原始值上加2，最终主存中的`obj.count`的值会是3。然而下图中两个加1操作是并行的，不管是线程A还是线程B先flush计算结果到主存，最终主存中的`obj.count`只会增加1次变成2，尽管一共有两次加1操作。 

![](/blog/images/201706_1/13.png)

####六、支撑Java内存模型的基础原理

1. 指令重排序
  在执行程序时，为了提高性能，编译器和处理器会对指令做重排序。但是，`JMM`确保在不同的编译器和不同的处理器平台之上，通过插入特定类型的`Memory Barrier`来禁止特定类型的编译器重排序和处理器重排序。重排序分三种类型：

- 编译器优化的重排序：编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。

- 指令级并行的重排序：现代处理器采用了指令级并行技术（`Instruction-Level Parallelism， ILP`）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。

- 内存系统的重排序：由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。

   从java源代码到最终实际执行的指令序列，会分别经历下面三种重排序：

   ![](/blog/images/201706_1/5.png)

​    上图中的 **`1` 属于编译器重排序，`2` 和 `3` 属于处理器重排序。**这些重排序都可能会导致多线程程序出现内存可见性问题。

- 对于编译器，`JMM `的编译器重排序规则会禁止特定类型的编译器重排序（**不是所有的编译器重排序都要禁止**）。
- 对于处理器重排序，`JMM`的处理器重排序规则会要求java编译器在生成指令序列时，插入特定类型的内存屏障（`Memory Barrier`）指令，通过内存屏障指令来禁止特定类型的处理器重排序（**不是所有的处理器重排序都要禁止**）。

   **`JMM`确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供了一致的内存可见性保证。**

2. 内存屏障（`Memory Barrier`）

​    上面讲到了通过内存屏障可以禁止特定类型处理器的重排序，从而让程序按我们预想的流程去执行。**内存屏障，又称内存栅栏，是一个CPU指令**，具有以下作用：

- 保证特定操作的执行顺序。
- 影响某些数据的内存可见性。
- 编译器和CPU能够重排序指令，保证最终相同的结果，尝试优化性能。插入一条 `Memory Barrier` 指令会告诉编译器和CPU：不管什么指令都不能和这条`Memory Barrier`指令重排序。

​    `Memory Barrier`所做的另外一件事是强制刷出各种`CPU cache`，如一个`Write-Barrier`（写入屏障）将刷出所有在`Barrier`之前写入`cache`的数据，因此，任何`CPU`上的线程都能读取到这些数据的最新版本。

​    如果一个变量是`volatile`修饰的，`JMM`会在写入这个字段之后插进一个`Write-Barrier`指令，并在读这个字段之前插入一个`Read-Barrier`指令。这意味着，如果写入一个`volatile`变量，就可以保证：

- 一个线程写入变量`a`后，任何线程访问该变量都会拿到最新值。在写入变量`a`之前的写入操作，其更新的数据对于其他线程也是可见的。因为`Memory Barrier`会刷出`cache`中的所有先前的写入。

​    现代的处理器使用写缓冲区来临时保存向内存写入的数据。写缓冲区可以保证指令流水线持续运行，它可以避免由于处理器停顿下来等待向内存写入数据而产生的延迟。同时，通过以批处理的方式刷新写缓冲区，以及合并写缓冲区中对同一内存地址的多次写，可以减少对内存总线的占用。虽然写缓冲区有这么多好处，但每个处理器（**指多个独立CPU而不是多核**）上的写缓冲区，仅仅对它所在的处理器可见。这个特性会对内存操作的执行顺序产生重要的影响：**处理器对内存的 读/写 操作的执行顺序，不一定与内存实际发生的 读/写 操作顺序一致。**为了具体说明，请看下面示例：

| Processor A | Processor B |
| ----------- | ----------- |
| a = 1; //A1 | b = 2; //B1 |
| x = b; //A2 | y = a; //B2 |

**初始状态：a = b = 0；处理器允许执行后得到结果：x = y = 0；**

​    假设处理器A和处理器B按程序的顺序并行执行内存访问，最终却可能得到x = y = 0的结果。具体的原因如下图所示：

![](/blog/images/201706_1/6.png)
​    

​    这里处理器A和处理器B可以同时把共享变量写入自己的写缓冲区（`A1，B1`），然后从内存中读取另一个共享变量（`A2，B2`），最后才把自己写缓存区中保存的脏数据刷新到内存中（`A3，B3`）。当以这种时序执行时，程序就可以得到`x = y = 0`的结果。

​    从内存操作实际发生的顺序来看，直到处理器A执行A3来刷新自己的写缓存区，写操作A1才算真正执行了。虽然处理器A执行内存操作的顺序为：`A1->A2`，但内存操作实际发生的顺序却是：`A2->A1`。此时，处理器A的内存操作顺序被重排序了。这里的关键是，由于写缓冲区仅对自己的处理器可见，它会导致处理器执行内存操作的顺序可能会与内存实际的操作执行顺序不一致。由于现代的处理器都会使用写缓冲区，因此现代的处理器都会允许对写-读操作重排序。

下面是常见处理器允许的重排序类型的列表：

|           | Load-Load | Load-Store | Store-Store | Store-Load | 存在数据依赖 |
| --------- | --------- | ---------- | ----------- | ---------- | ------ |
| sparc-TSO | N         | N          | N           | Y          | N      |
| x86       | N         | N          | N           | Y          | N      |
| ia64      | Y         | Y          | Y           | Y          | N      |
| PowerPC   | Y         | Y          | Y           | Y          | N      |

上表单元格中的 “N” 表示处理器不允许两个操作重排序，“Y” 表示允许重排序。

从上表我们可以看出：

- 常见的处理器都允许Store-Load重排序。
- 常见的处理器都不允许对存在数据依赖的操作做重排序。
- sparc-TSO和x86拥有相对较强的处理器内存模型，它们仅允许对写-读操作做重排序（因为它们都使用了写缓冲区）。

**注：**

1. sparc-TSO是指以TSO(Total Store Order)内存模型运行时，sparc处理器的特性。
2. 上表中的x86包括x64及AMD64。
3. 由于ARM处理器的内存模型与PowerPC处理器的内存模型非常类似，本文将忽略它。
4. 数据依赖性后文会专门说明。

为了保证内存可见性，**`Java`编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。**`JMM`把内存屏障指令分为下列四类：

| 屏障类型                | 指令示例                        | 说明                                       |
| ------------------- | --------------------------- | ---------------------------------------- |
| LoadLoad Barriers   | Load1; LoadLoad; Load2;     | 确保`Load1`数据的装载，之前于`Load2`及所有后续装载指令的装载。   |
| StoreStore Barriers | Store1; StoreStore; Store2; | 确保`Store1`数据对其他处理器可见（刷新到内存），之前于`Store2`及所有后续存储指令的存储。 |
| LoadStore Barriers  | Load1; LoadStore; Store2;   | 确保`Load1`数据装载，之前于`Store2`及所有后续的存储指令刷新到内存。 |
| StoreLoad Barriers  | Store1; StoreLoad; Load2;   | 确保`Store1`数据对其他处理器变得可见（刷新到内存），之前于`Load2`及所有后续装载指令的装载。StoreLoad Barriers会使该屏障之前的所有内存访问指令（存储和装载指令）完成之后，才执行该屏障之后的内存访问指令。 |

​    `StoreLoad Barriers` 是一个 “全能型” 的屏障，它同时具有其他三个屏障的效果。现代的多处理器大都支持该屏障。执行该屏障开销会很昂贵，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中（`buffer fully flush`）。

3. happens-before（先行发生原则）

​    Java语言定义了先行发生原则来辅助`volatile`和`synchronized`等来保证内存模型所有操作的有序性，它是判断数据是否存在竞争、线程是否安全的主要依据。

​    先行发生原则是Java内存模型中定义的两项操作之间的偏序关系，如果说操作A先行发生于操作B，其实就是说在发生操作B之前，操作A所产生的影响能被操作B观察到，“影响”包括修改了内存中共享变量的值，发送了消息，调用了方法等。

​    下面是Java内存模型下一些“天然的”先行发生原则，这些先行发生原则无需任何同步机制协助就已经存在，可以在编码中直接使用。如果两个操作之间的关系不在此列，并且无法从下列规则中推导出来的话，它们就是没有顺序性保障，虚拟机接可以对它们随意进行重排序。

- 程序次序原则（Program Order Rule）

  在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。



- 管程锁定规则(`Monitor Lock Rule`)

​    对某个锁的`unlock`操作先行发生于后面对同一个锁的`lock`操作。这里必须强调的是同一个锁，这里的“后面”是指时间上的先后顺序。

- `volatile`变量规则(`Volatile Variable Rule`)

​    对一个volatile变量的写操作先行发生于后面对这个变量的读操作，这里的“后面”同样是指时间上的先后顺序。也就是说，某个线程对`volatile`变量写入某个值后，能立即被其它线程读取到。

- 线程启动规则(`Thread Start Rule`)

​    Thread对象的start方法先行发生于此线程的每个动作。

- 线程终止规则(`Thread Termination Rule`)

​    线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过`Thread.join()`方法结束，`Thread.isAlive()`的返回值等手段检测到线程是否已经终止运行。

- 线程中断规则(`Thread Interruption Rule`)

​    对线程`interrupt()`方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过`Thread.interrupted()`方法检测到是否有中断发生。

- 对象终结规则(`Thread Termination Rule`)

​    一个对象的初始化完成(构造函数执行结束)先行发生于它的`finalize()`方法的开始。

- 传递性(`Transitivity`)

​    如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。

​    其中程序次序规则，管程锁定规则，`volatile`变量规则，传递性规则经常用来推断先行发生关系。需要注意的是，**只有满足以上几条先行发生原则的时间上的先后操作具备顺序可靠性，时间上的先后顺序不能得出先行发生关系**，如下示例代码所示：

```java
private int value = 0;

public void setValue(int value) {
	this.value=value;
}

public int getValue() {
	return value;
}
```

​    假设存在线程A和线程B，线程A先（时间上的先后）调用了`setValue(1)`，然后线程B调用了同一个对象的`getValue()`，那么线程B收到的返回值是不确定的，由于工作内存和主内存同步存在延迟，也由于可能存在重排序现象。 虽然时间上线程A的`setValue()`操作先于线程B的 `getValue()` 操作，但是并不能推断出线程A的`setValue()`操作先行发生于线程B的`getValue()`操作，如果有这种先行发生关系，那么可以推断出线程B的`getValue()`操作获得的值。

​    如果我们给`getValue()`方法和`setValue()`方法添加 `synchronized` 关键字，就能利用管程锁定规则推断出线程A的`setValue`操作先行发生于线程B的`getValue`操作，或者我们也可以将`value`定义为 `volatile` 变量，也能利用 `volatile` 变量规则推断出先行发生关系。

​    **先行发生关系也不能推断出时间上的先后执行顺序**，示例代码如下所示：

```java
int i=1;
int j=2;
```

​    根据程序次序规则，我们可以推断出`int i=1`的操作先行发生于`int j=2`的操作，但是`int j=2`的代码完全有可能先被处理器执行（时间上的先后），这就是重排序，虚拟机规范是允许这种特性存在的，虚拟机可利用这种特性提高性能。

**注意：**

  两个操作之间具有 `happens-before` 关系，并不意味前一个操作必须要在后一个操作之前执行。仅仅要求前一个操作的执行结果，对于后一个操作是可见的，且前一个操作按顺序排在后一个操作之前。

####七、volatile关键字

1. volatile的特性

**`volatile`关键字是Java虚拟机提供的最轻量级的同步机制**，当一个变量定义为`volatile`后，他具备两种特性：

- 保证此变量对所有线程的可见性（当某个线程修改了这个变量的值，其他线程可以立刻得知）。
- 禁止指令重排序优化。

理解`volatile`特性的一个好方法是：把对`volatile`变量的单个读/写，看成是使用同一个锁对这些单个读/写操作做了同步。下面我们通过具体的示例来说明，请看下面的示例代码：

```java
class VolatileFeaturesExample {
    //使用volatile声明64位的long型变量
    volatile long vl = 0L;

    public void set(long l) {
        vl = l;   //单个volatile变量的写
    }

    public void getAndIncrement () {
        vl++;    //复合（多个）volatile变量的读/写
    }

    public long get() {
        return vl;   //单个volatile变量的读
    }
}
```

假设有多个线程分别调用上面程序的三个方法，这个程序在语义上和下面程序等价：

```java
class VolatileFeaturesExample {
    long vl = 0L;               // 64位的long型普通变量

    //对单个的普通 变量的写用同一个锁同步
    public synchronized void set(long l) {             
       vl = l;
    }

    public void getAndIncrement () { //普通方法调用
        long temp = get();           //调用已同步的读方法
        temp += 1L;                  //普通写操作
        set(temp);                   //调用已同步的写方法
    }
    public synchronized long get() { 
        //对单个的普通变量的读用同一个锁同步
        return vl;
    }
}
```

如上面示例程序所示，对一个`volatile`变量的单个读/写操作，与对一个普通变量的读/写操作使用同一个锁（`synchronized`）来同步，它们之间的执行效果相同。

锁的`happens-before`规则保证释放锁和获取锁的两个线程之间的内存可见性，这意味着对一个`volatile`变量的读，总是能看到（任意线程）对这个`volatile`变量最后的写入。

简而言之，`volatile`变量自身具有下列特性：

- 可见性：对一个`volatile`变量的读，总是能看到（任意线程）对这个`volatile`变量最后的写入。
- 原子性：对任意单个`volatile`变量的读/写具有原子性（即使是64位的 `long` 型 和 `double` 型变量，只要它是`volatile`变量，对该变量的读写就将具有原子性），但类似于`volatile++`这种复合操作不具有原子性。

2. `volatile`的写-读建立的`happens before`关系

上面讲的是`volatile`变量自身的特性，对程序员来说，`volatile`对线程的内存可见性的影响比`volatile`自身的特性更为重要，也更需要我们去关注。

从**`JSR-133` （Java内存模型与线程规范）**开始，`volatile`变量的写-读可以实现线程之间的通信。从内存语义的角度来说，`volatile`与锁有相同的效果：

- volatile写和锁的释放有相同的内存语义。
- volatile读与锁的获取有相同的内存语义。

请看下面使用volatile变量的示例代码：

```java
class VolatileExample {
    int a = 0;
    volatile boolean flag = false;

    public void writer() {
        a = 1;                   //1
        flag = true;               //2
    }

    public void reader() {
        if (flag) {                //3
            int i =  a;           //4
            ……
        }
    }
}
```

假设线程A执行`writer()` 方法之后，线程B执行 `reader()` 方法。根据 `happens before` 规则，这个过程建立的`happens before` 关系可以分为两类：

- 根据程序次序规则：`1` `happens before` `2`；`3` `happens before` `4`。
- 根据`volatile`规则：`2` `happens before` `3`。
- 根据`happens before` 的传递性规则：`1` `happens before` `4`。

上述`happens before` 关系的图形化表现形式如下：

![](/blog/images/201706_1/18.png)

​    在上图中，每一个箭头链接的两个节点，代表了一个`happens before` 关系。黑色箭头表示程序顺序规则；橙色箭头表示`volatile`规则；蓝色箭头表示组合这些规则后提供的`happens before`保证。这里A线程写一个`volatile`变量后，B线程读同一个`volatile`变量。A线程在写`volatile`变量之前所有可见的共享变量，在B线程读同一个`volatile`变量后，将立即变得对B线程可见。

3. `volatile`写-读的内存语义

- `volatile`写的内存语义如下：

  **当写一个`volatile`变量时，`JMM`会把该线程对应的本地内存中的共享变量刷新到主内存。**

​    以上面示例程序`VolatileExample`为例，假设线程A首先执行`writer()`方法，随后线程B执行`reader()`方法，初始时两个线程的本地内存中的`flag`和`a`都是初始状态。下图是线程A执行`volatile`写后，共享变量的状态示意图：

![](/blog/images/201706_1/19.png)

如上图所示，线程A在写`flag`变量后，本地内存A中被线程A更新过的两个共享变量的值被刷新到主内存中。此时，本地内存A和主内存中的共享变量的值是一致的。

- `volatile`读的内存语义如下：

  **当读一个`volatile`变量时，`JMM`会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。**

下面是线程B读同一个`volatile`变量后，共享变量的状态示意图：

![](/blog/images/201706_1/20.png)

​    如上图所示，在读`flag`变量后，本地内存B已经被置为无效。此时，线程B必须从主内存中读取共享变量。线程B的读取操作将导致本地内存B与主内存中的共享变量的值也变成一致的了。如果我们把`volatile`写和`volatile`读这两个步骤综合起来看的话，在读线程B读一个`volatile`变量后，写线程A在写这个`volatile`变量之前所有可见的共享变量的值都将立即变得对读线程B可见。

下面对`volatile`写和`volatile`读的内存语义做个总结：

- 线程A写一个`volatile`变量，实质上是线程A向接下来将要读这个`volatile`变量的某个线程发出了（其对共享变量所在修改的）消息。
- 线程B读一个`volatile`变量，实质上是线程B接收了之前某个线程发出的（在写这个`volatile`变量之前对共享变量所做修改的）消息。
- 线程A写一个`volatile`变量，随后线程B读这个`volatile`变量，这个过程实质上是线程A通过主内存向线程B发送消息。

4. `volatile`内存语义的实现

下面，让我们来看看`JMM`如何实现`volatile`写/读的内存语义。

前文我们提到过**重排序分为编译器重排序和处理器重排序**。为了实现`volatile`内存语义，`JMM`会分别限制这两种类型的重排序类型。下面是`JMM`针对编译器制定的`volatile`重排序规则表：

| 是否能重排序    | 第二个操作 |           |           |
| --------- | ----- | --------- | --------- |
| 第一个操作     | 普通读/写 | volatile读 | volatile写 |
| 普通读/写     |       |           | NO        |
| volatile读 | NO    | NO        | NO        |
| volatile写 |       | NO        | NO        |

举例来说，第三行最后一个单元格的意思是：在程序顺序中，当第一个操作为普通变量的读或写时，如果第二个操作为`volatile`写，则编译器不能重排序这两个操作。

从上表我们可以看出：

- 当第二个操作是`volatile`写时，不管第一个操作是什么，都不能重排序。这个规则确保`volatile`写之前的操作不会被编译器重排序到`volatile`写之后。
- 当第一个操作是`volatile`读时，不管第二个操作是什么，都不能重排序。这个规则确保`volatile`读之后的操作不会被编译器重排序到`volatile`读之前。
- 当第一个操作是`volatile`写，第二个操作是`volatile`读时，不能重排序。

为了实现`volatile`的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能，为此，`JMM`采取保守策略。下面是基于保守策略的`JMM`内存屏障插入策略：

- 在每个`volatile`写操作的前面插入一个`StoreStore`屏障。
- 在每个`volatile`写操作的后面插入一个`StoreLoad`屏障。
- 在每个`volatile`读操作的后面插入一个`LoadLoad`屏障。
- 在每个`volatile`读操作的后面插入一个`LoadStore`屏障。

上述内存屏障插入策略非常保守，但它可以保证在任意处理器平台，任意的程序中都能得到正确的`volatile`内存语义。

下面是保守策略下，`volatile`写插入内存屏障后生成的指令序列示意图：

![](/blog/images/201706_1/21.png)

​    上图中的`StoreStore`屏障可以保证在`volatile`写之前，其前面的所有普通写操作已经对任意处理器可见了。这是因为`StoreStore`屏障将保障上面所有的普通写在`volatile`写之前刷新到主内存。

​    最后的`StoreLoad`屏障的作用是避免`volatile`写与后面可能有的`volatile`读/写操作重排序。因为编译器常常无法准确判断在一个`volatile`写的后面，是否需要插入一个`StoreLoad`屏障（如：一个`volatile`写之后方法立即`return`）。

​    为了保证能正确实现`volatile`的内存语义，`JMM` 有两种保守策略可选择：**在每个`volatile`写的后面或在每个`volatile`读的前面插入一个`StoreLoad`屏障。**

​    从整体执行效率的角度考虑，`JMM`选择了在每个`volatile`**写的后面**插入一个`StoreLoad`屏障。因为`volatile`写-读内存语义的常见使用模式是：一个写线程写volatile变量，多个读线程读同一个volatile变量。当读线程的数量大大超过写线程时，选择在volatile写之后插入StoreLoad屏障将带来可观的执行效率的提升。从这里我们可以看到JMM在实现上的一个特点：**首先确保正确性，然后再去追求执行效率。**

​    下面是在保守策略下，volatile读插入内存屏障后生成的指令序列示意图：

![](/blog/images/201706_1/22.png)
​    上述volatile写和volatile读的内存屏障插入策略非常保守。在实际执行时，只要不改变volatile写-读的内存语义，编译器可以根据具体情况省略不必要的屏障。下面我们通过具体的示例代码来说明：

```java
class VolatileBarrierExample {
    int a;
    volatile int v1 = 1;
    volatile int v2 = 2;
    
    void readAndWrite() {
        int i = v1;           //第一个volatile读
        int j = v2;           //第二个volatile读
        a = i + j;            //普通写
        v1 = i + 1;           //第一个volatile写
        v2 = j * 2;           //第二个 volatile写
    }
    
    //...                     //其他方法
}
```

​    针对`readAndWrite()`方法，编译器在生成字节码时可以做如下的优化：

![](/blog/images/201706_1/23.png)

​    注意，最后的`StoreLoad`屏障不能省略。因为第二个`volatile`写之后，方法立即`return`。此时编译器可能无法准确断定后面是否会有`volatile`读或写，为了安全起见，编译器常常会在这里插入一个`StoreLoad`屏障。

​    上面的优化是针对任意处理器平台，由于不同的处理器有不同“松紧度”的处理器内存模型，内存屏障的插入还可以根据具体的处理器内存模型继续优化。以`x86`处理器为例，上图中除最后的`StoreLoad`屏障外，其它的屏障都会被省略。

前面保守策略下的`volatile`读和写，在 `x86`处理器平台可以优化成：

![](/blog/images/201706_1/24.png)

5. `volatile` 与 `synchronized` 的比较

   `volatile`本质是在告诉`JVM`当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读取。`synchronized`则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。

   它们之间的区别可以总结为以下几点：

   - `volatile`仅能使用在变量级别。`synchronized`则可以使用在变量、方法、和类级别的。

   - **`volatile`仅能实现变量的修改可见性，并不能保证原子性。`synchronized`则可以保证变量的修改可见性和原子性。**

   - `volatile`不会造成线程的阻塞。`synchronized`可能会造成线程的阻塞。
   - `volatile`标记的变量不会被编译器优化。`synchronized`标记的变量可以被编译器优化。

​    关于`volatile`变量的可见性，经常会被误解，认为以下描述成立：

​    **volatile变量对所有线程是立即可见的，对`volatile`变量所有的写操作都能立即反应到其他线程中，`volatile`变量在各个线程中的值总是一致的，所以基于`volatile`变量的运算在并发操作下是安全的。**

   其实`volatile`变量在各个线程的工作内存中不存在一致性问题，但是Java里面的运算并非原子操作，导致`volatile`变量的运算在并发下一样不是安全的，我们通过以下代码演示说明：

```java
public class VolatileTest {

    private static volatile int race = 0;

    private static final int THREADS_COUNT = 20;

    private static final CountDownLatch latch = new CountDownLatch(THREADS_COUNT);

    public static void increase() {
        race++;
    }

    public static void main(String[] args) {

        for (int n = 0; n < THREADS_COUNT; n++) {
            new Thread(new Runnable() {
                public void run() {
                    for (int i = 0; i < 10000; i++) {
                        increase();
                    }
                    latch.countDown();
                }
            }).start();
        }

        try {
            // 等待所有线程都结束
            latch.await();
        } catch (InterruptedException e) {
            System.out.println("exception: " + e.getMessage());
        }

        System.out.println("race: " + race);
    }
}
```
这段代码发起20个线程对`volatile`修饰的`race`变量进行`10000`次自增操作，预期结果应该是`200000`，但是每次运行得到的结果都不一样。问题就出在自增运算`race++`中，通过 `javap -verbose VolatileTest` 反编译代码的class文件发现只有一行代码的`increase()`方法在`Class`文件中是由四条指令构成的。
```java
......
  
public static void increase();

    descriptor: ()V
    flags: ACC_PUBLIC, ACC_STATIC
    Code:
      stack=2, locals=0, args_size=0
         0: getstatic     #2                  // Field race:I
         3: iconst_1
         4: iadd
         5: putstatic     #2                  // Field race:I
         8: return
      LineNumberTable:
        line 32: 0
        line 33: 8    
......
```
从字节码层面上就很容易分析出原因：

​    当`getstatic`指令吧race的值渠道操作栈顶时，`volatile`关键字保证了`race`的值在此时是正确的，但是在执行`iconst_1、iadd`这些指令的时候，其他线程可能已经把`race`的值加大了，而在操作栈顶的值就变成了过去的数据，所以`putstatic`指令执行后可能就把较小的`race`值同步回主内存之中。



#### 八、参考文献

- 《深入理解Java虚拟机：JVM高级特性与最佳实践》，周志明著
- [深入理解java内存模型系列文章](http://ifeve.com/java-memory-model-0/)
- [全面理解Java内存模型](http://blog.csdn.net/suifeng3051/article/details/52611310)

